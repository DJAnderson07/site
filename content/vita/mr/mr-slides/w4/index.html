<!DOCTYPE html>
<html>
  <head>
    <title>Uncertainty and model assumptions</title>
    <meta charset="utf-8">
    <meta name="author" content="Daniel Anderson" />
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/uo.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/uo-fonts.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/hygge.css" rel="stylesheet" />
    <link rel="stylesheet" href="custom.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Uncertainty and model assumptions
### Daniel Anderson
### Week 4

---




# Agenda 

* Uncertainty 
  + Standard errors
  + Confidence intervals &amp; p values
* Sample interpretations
* Model Assumptions 
  + LINE acronym for assumptions
  + Importance of exploring and visualizing your data first 
* Intro to model Diagnostics
* Lab


---
class: inverse middle center
background-image:url(../img/chalkboard.jpg)
background-size:cover

# What questions do you have?

---
# First thing's first
Let's get some data!

[demo]

Please follow along. We'll load the `hsb2.sav` file.




---
class: inverse middle center
background-image:url(../img/celebrate.jpg)
background-size:cover

# Testing for significance

---
# Variance of the estimate
Recall the residual standard error 

.Large[
$$
s\_{y.x} = \sqrt{\frac{\sum (Y - Y')^2}{df}} =  \sqrt{\frac{ss_{res}}{df}}
$$

$$
df = n - k - 1
$$

]


--
* A quick note on notation
  + When we use `arm::display()` it reports `\(k\)` as the number of estimated
    parameters. (this is pretty standard and actually what I usually use)
  + Pedhazur uses `\(k\)` to indicate the number of *predictors* in the model
  + I'll stick with Pedhazur's even though it's a little unnatural for me.

---
## In the simple linear regression case
* The standard error of `\(b\)` is

.Large[
$$
s\_b = \frac{s\_{y.x}}{\sqrt{\sum x^2}}
$$
]


--
In words... the model residual standard error divided by the (square root of
the) sum of the squared deviations

--
### Quick verification
.gray[Do it with me!]

* First, let's fit a model with students' reading scores predicting their
mathematics scores. 

---


```r
m1 &lt;- lm(math ~ read, d)
```

--


```r
arm::display(m1, detail = TRUE)
```

```
## lm(formula = math ~ read, data = d)
##             coef.est coef.se t value Pr(&gt;|t|)
## (Intercept) 21.04     2.59    8.12    0.00   
## read         0.61     0.05   12.44    0.00   
## ---
## n = 200, k = 2
## residual sd = 7.04, R-Squared = 0.44
```

* Let's interpret the results

---
# Confirm

.Large[
$$
s\_b = \frac{s\_{y.x}}{\sqrt{\sum x^2}}
$$
]

--

* We'll focus on calculating the denominator, and we'll just plug-in the
numerator. 

--
* What's the sum of squares again?

---
First, calculate the deviations (note - we're creating a new variable, `dev`,
  then selecting our original `read` variable and `dev` only).


```r
mean(d$read)
```

```
## [1] 52.23
```

```r
ss &lt;- d %&gt;%
  select(read)

ss %&gt;%
* mutate(dev = read - mean(read)) %&gt;%
  head()
```

```
## # A tibble: 6 x 2
##    read        dev
##   &lt;dbl&gt;      &lt;dbl&gt;
## 1    57   4.77    
## 2    68  15.77    
## 3    44  -8.230000
## 4    63  10.77    
## 5    47  -5.230000
## 6    44  -8.230000
```

---
# Square the deviations


```r
ss %&gt;%
  mutate(dev = read - mean(read),
*        dev2 = dev^2) %&gt;%
  head()
```

```
## # A tibble: 6 x 3
##    read        dev      dev2
##   &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;
## 1    57   4.77      22.7529 
## 2    68  15.77     248.6929 
## 3    44  -8.230000  67.73290
## 4    63  10.77     115.9929 
## 5    47  -5.230000  27.35290
## 6    44  -8.230000  67.73290
```

---
# Sum the squared deviations


```r
ss %&gt;%
  mutate(dev = read - mean(read),
         dev2 = dev^2,
*        sum_squares = sum(dev2)) %&gt;%
  head()
```

```
## # A tibble: 6 x 4
##    read        dev      dev2 sum_squares
##   &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;
## 1    57   4.77      22.7529     20919.42
## 2    68  15.77     248.6929     20919.42
## 3    44  -8.230000  67.73290    20919.42
## 4    63  10.77     115.9929     20919.42
## 5    47  -5.230000  27.35290    20919.42
## 6    44  -8.230000  67.73290    20919.42
```

---
# Square Root


```r
ss %&gt;%
  mutate(dev = read - mean(read),
         dev2 = dev^2,
         sum_squares = sum(dev2),
*        denom = sqrt(sum_squares)) %&gt;%
  head()
```

```
## # A tibble: 6 x 5
##    read        dev      dev2 sum_squares    denom
##   &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;
## 1    57   4.77      22.7529     20919.42 144.6355
## 2    68  15.77     248.6929     20919.42 144.6355
## 3    44  -8.230000  67.73290    20919.42 144.6355
## 4    63  10.77     115.9929     20919.42 144.6355
## 5    47  -5.230000  27.35290    20919.42 144.6355
## 6    44  -8.230000  67.73290    20919.42 144.6355
```

---
# SE estimate


```r
7.04 / 144.6355
```

```
## [1] 0.04867408
```

```r
arm::display(m1, digits = 4, detail = TRUE)
```

```
## lm(formula = math ~ read, data = d)
##             coef.est coef.se t value Pr(&gt;|t|)
## (Intercept) 21.0382   2.5894  8.1246  0.0000 
## read         0.6051   0.0487 12.4378  0.0000 
## ---
## n = 200, k = 2
## residual sd = 7.0371, R-Squared = 0.44
```

---
# In the MR case
* We have to remove the shared variance

.Large[
$$
s\_{b\_{y1.2}} = \frac{s\_{y.x}}{\sqrt{\sum x\_1^2(1-r\_{x\_1x\_2}^2)}}
$$
]

---
# Quick verification

Let's fit a second model, this time with reading and writing predicting
students' math scores

--


```r
m2 &lt;- lm(math ~ read + write, d)
arm::display(m2, detail = TRUE, digits = 4)
```

```
## lm(formula = math ~ read + write, data = d)
##             coef.est coef.se t value Pr(&gt;|t|)
## (Intercept) 12.8651   2.8216  4.5595  0.0000 
## read         0.4169   0.0565  7.3817  0.0000 
## write        0.3411   0.0611  5.5832  0.0000 
## ---
## n = 200, k = 3
## residual sd = 6.5553, R-Squared = 0.52
```

---

```r
arm::display(m2, digits = 4, detail = TRUE)
```

```
## lm(formula = math ~ read + write, data = d)
##             coef.est coef.se t value Pr(&gt;|t|)
## (Intercept) 12.8651   2.8216  4.5595  0.0000 
## read         0.4169   0.0565  7.3817  0.0000 
## write        0.3411   0.0611  5.5832  0.0000 
## ---
## n = 200, k = 3
## residual sd = 6.5553, R-Squared = 0.52
```

```r
# Compute correlation
x1x2_cor &lt;- cor(d$read, d$write)

# Compute sums-of squares for reading (in a single line of code)
ss_read &lt;- sum((d$read - mean(d$read))^2)

6.5553 / sqrt(ss_read*(1 - x1x2_cor^2))
```

```
## [1] 0.05648365
```

---
# Challenge
Can you calculate the standard error for `write` by hand? 

Follow these steps:
1. Compute the correlation, as in the prior slide
2. Compute the sums of squares for `write`
3. Use the code we used before `6.555315 / sqrt(ss_read*(1 - x1x2_cor^2))`,
   but insert your sums of squares estimate.

---
# What is the standard error?

--
The variance of the estimate (standard deviation) over (theoretically) repeated
samples. 


--
.Large[üßê]

---
# Simulating the process

[demo]

Note - this is purely for demonstration. Please DO NOT follow along. If you're
interested in the code, play with it after class and we can chat if you want.

--

.code-bg-red[


```r
set.seed(8675309)
samples &lt;- replicate(1000, 
                     d[sample(1:nrow(d),
                              size = nrow(d),
                              replace = TRUE), ],
                     simplify = FALSE)
```
]

.gray[Trying something new - chunks in this background color indicate that you
don't need to follow along, and it's generally not recommended]


---
# What's the prior code doing?

![](../img/bootstrap.png)


---
# First 4 rows of first 2 datasets

.code-bg-red[


```r
map(samples[1:2], ~head(., 4))
```

```
## [[1]]
## # A tibble: 4 x 11
##      id race     ses   schtyp prog   read write  math science socst Gender
##   &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; 
## 1   103 white    high  public acad‚Ä¶    76    52    64      64    61 Male  
## 2   173 white    low   public gene‚Ä¶    50    62    61      63    51 Female
## 3   138 white    midd‚Ä¶ public voca‚Ä¶    43    57    40      50    51 Female
## 4    10 hispanic midd‚Ä¶ public gene‚Ä¶    47    54    49      53    61 Female
## 
## [[2]]
## # A tibble: 4 x 11
##      id race  ses    schtyp  prog    read write  math science socst Gender
##   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; 
## 1    71 white middle public  gener‚Ä¶    57    62    56      58    66 Female
## 2    26 asian high   public  acade‚Ä¶    60    59    62      61    51 Female
## 3   195 white middle private gener‚Ä¶    57    57    60      58    56 Male  
## 4   170 white high   public  acade‚Ä¶    47    62    61      69    66 Male
```

]

---
# Fit a model to each sample

.code-bg-red[


```r
models &lt;- map(samples, ~lm(math ~ read + write, .))
```

]

---

.code-bg-red[


```r
boot_ests &lt;- map_df(models, 
                    ~data.frame(coef = coef(.),
                                param = c("intercept",
                                          "b1_read",
                                          "b2_write")), 
                    .id = "iteration") %&gt;% 
  spread(param, coef) %&gt;%
  mutate(iteration = as.numeric(iteration)) %&gt;%
  arrange(iteration)
head(boot_ests, 4)
```

```
##   iteration   b1_read  b2_write intercept
## 1         1 0.4832635 0.3583211   8.71417
## 2         2 0.4130313 0.3186412  14.64451
## 3         3 0.4705402 0.3276435  10.79783
## 4         4 0.3903003 0.3739700  12.73905
```

```r
boot_ests %&gt;% 
  summarize(int_sd = sd(intercept),
            b1_sd  = sd(b1_read),
            b2_sd  = sd(b2_write))
```

```
##     int_sd      b1_sd      b2_sd
## 1 2.620572 0.05793157 0.06139615
```
]

---
## Looking back at our parametric estimates


```r
arm::display(m2)
```

```
## lm(formula = math ~ read + write, data = d)
##             coef.est coef.se
## (Intercept) 12.87     2.82  
## read         0.42     0.06  
## write        0.34     0.06  
## ---
## n = 200, k = 3
## residual sd = 6.56, R-Squared = 0.52
```

---
# Visualizing the uncertainty



.code-bg-red[

![](w4_files/figure-html/visualize-uncertainty-1.png)&lt;!-- --&gt;
]
These are bootstrapped standard errors

---
# Another visualization
(This one is with simple linear regression)

.code-bg-red[

.pull-left[

![](w4_files/figure-html/slope-vis1-1.png)&lt;!-- --&gt;

]
]

.pull-right[

![](w4_files/figure-html/slope-vis2-1.png)&lt;!-- --&gt;

]

---
# The `\(t\)` statistic
* The coefficients, divided by their standard error, provides a `\(t\)`-distributed
statistic.

--

  + What's the difference between a `\(t\)` distribution and a normal distribution?

---
![](w4_files/figure-html/t-normal1-1.png)&lt;!-- --&gt;

---
# Fat tails
* When the `\(df\)` are small, the tails are fatter
* This implies you need a bigger `\(t\)` to reach `\(p &lt; 0.05\)`


---
![](w4_files/figure-html/t-normal2-1.png)&lt;!-- --&gt;

---
# Practical takeaways
1. The size of the SE will depend on `\(n\)` because 
`\(s_{y.x} = \sqrt{\frac{ss_{res}}{df}}\)` and `\(df = n - k - 1\)` (using Pedhazur's
notation where `\(k\)` = number of predictors)

--
2. Because `coef/se = t`, larger standard errors will result in smaller `\(t\)`
statistics.

--
3. Smaller sample sizes also require larger `\(t\)` to be significant


--
### How do you get a larger `\(t\)`

--
Bigger coefficients, smaller standard errors

---
# Overall model test
* The model `\(R^2\)` represents the proportion the residual variance has been
reduced.

.large[
$$
R^2 = \frac{SS\_{reg}}{SS\_{y}}
$$
]

* Often we want to know if this reduction is significantly different than zero.
  We can evaluate this using an `\(F\)` test.

--

.pull-left[
Using `\(R^2\)`
.large[
$$
F = \frac{R^2/k}{(1-R^2)/(n - k - 1)}
$$
]
]

.pull-right[
or using the sums of squares

.large[
$$
F = \frac{SS\_{reg}/df\_{reg}}{SS\_{res}/df\_{res}}
$$
]
]

---
class: middle right
background-image: url(https://upload.wikimedia.org/wikipedia/commons/thumb/7/74/F-distribution_pdf.svg/325px-F-distribution_pdf.svg.png)
background-size:contain

# F Distribution

---
# Pop quiz

Can the model `\(R^2\)` be significant even if **none** of the individual
coefficients are?

--
### Of course!

&lt;div align = "center"&gt;
&lt;img src = ../img/high-collinearity.png height = 300&gt;
&lt;/div&gt;

.footnote[Figure from Tu, Kellett, Clerehugh, &amp; Gilthorpe (2005): 
  https://www.nature.com/articles/4812743.pdf?origin=ppub]

---
# Confidence intervals
Almost always preferable to p-values alone


--

* Practically: `\(b \pm 2*s_b\)`

--
* Why `\(2*s_b\)`?


--
### Actually:

.Large[
$$
b \pm t\_{(\frac{\alpha}{2},df)}s\_b
$$
]

---
# Approximating example


```r
arm::display(m2, digits = 4, detail = TRUE)
```

```
## lm(formula = math ~ read + write, data = d)
##             coef.est coef.se t value Pr(&gt;|t|)
## (Intercept) 12.8651   2.8216  4.5595  0.0000 
## read         0.4169   0.0565  7.3817  0.0000 
## write        0.3411   0.0611  5.5832  0.0000 
## ---
## n = 200, k = 3
## residual sd = 6.5553, R-Squared = 0.52
```

--

.pull-left[

```r
12.8651 - 2*2.8216
```

```
## [1] 7.2219
```

```r
12.8651 + 2*2.8216
```

```
## [1] 18.5083
```
]


--


.pull-right[

```r
confint(m2)
```

```
##                 2.5 %     97.5 %
## (Intercept) 7.3006103 18.4295249
## read        0.3055581  0.5283391
## write       0.2206314  0.4616124
```
]

---
The `qt` function returns the exact `\(t\)` value, which in this case is 
-1.967596. Compare that to a `\(Z\)` value, of 
-1.959964 (because we have 312 `\(df\)`).

--

.pull-left[
.code-bg-red[

```r
12.8651 + qt(0.05/2, 197)*2.8216
```

```
## [1] 7.300682
```

```r
12.8651 - qt(0.05/2, 197)*2.8216
```

```
## [1] 18.42952
```
]
]


.pull-right[

```r
confint(m2)
```

```
##                 2.5 %     97.5 %
## (Intercept) 7.3006103 18.4295249
## read        0.3055581  0.5283391
## write       0.2206314  0.4616124
```
]


---
## Want it to match **exactly** exactly?



```r
confint(m2)
```

```
##                 2.5 %     97.5 %
## (Intercept) 7.3006103 18.4295249
## read        0.3055581  0.5283391
## write       0.2206314  0.4616124
```
.code-bg-red[

```r
coef(m2)[2] + qt(0.025, m2$df.residual)* summary(m2)$coefficients[2, 2]
```

```
##      read 
## 0.3055581
```

```r
coef(m2)[2] + qt(0.975, m2$df.residual)* summary(m2)$coefficients[2, 2]
```

```
##      read 
## 0.5283391
```
]

---
# Using the bootstrap estimates

.code-bg-red[

```r
boot_ests %&gt;% 
  summarize(int_lower = quantile(intercept, 0.025),
            int_upper = quantile(intercept, 0.975),
            b1_lower = quantile(b1_read, 0.025),
            b1_upper = quantile(b1_read, 0.975),
            b2_lower = quantile(b2_write, 0.025),
            b2_upper = quantile(b2_write, 0.975))
```

```
##   int_lower int_upper  b1_lower  b1_upper  b2_lower  b2_upper
## 1  7.714023  18.26199 0.3035328 0.5277044 0.2214116 0.4611397
```
]

---
# How do we interpret these?

If your model is correct, the interval will contain the true population value
95% of the time.

--

### Not probability-based
* Frequentist stats (which this is) assumes a single "true" population value.
* Our CI comes from the estimated sampling distribution for the point estimate.
* Probability of the "true" value lying within those bounds is 0/1
* Thus, literally, "confidence" based - the wider the interval, the more
confident we can be. 

---
# p values
* A very similar process can be used to estimate the exact p value 


--
### What does a p-value represent?

&gt; the probability of obtaining data as extreme, or more extreme, than those 
  observed if the null hypothesis is correct and the model assumptions are met.



--
* If the value is outside the bounds of the CI, it is "significant"
  + i.e., we can claim that the observed result is unlikely due to random
    sampling variability

---
# But
* The prior slide holds **only if we meet our model-assumptions**
  + If you don't meet your model assumptions, this is usually what gets messed
    up first.

.gray[(we may do an activity later in the term to see how bad things have to
       get before things become problematic)]

---
# Before we move on
* This discussion is fairly technical and meant as background
  + e.g., "Where do these numbers actually come from?"

--
* Practically, you should be able to
  + Find and interpret SEs
  + Estimate and interpret CIs
  + Correctly interpret *p* values


--
### Let's practice

---
# Fit the corresponding model
$$
read_i = b_0 + b_1(SES_i) + b_2(math_i) + e
$$

Discuss at your table:
* What do the coefficients represent
* What does the standard error for math represent?
* What does the standard error for the SES-low represent?
* Interpret the p-values for the SES coefficients
* Estimate and interpret the 95% CIs for the model

---

```r
d &lt;- d %&gt;%
  mutate(ses = factor(ses))

m3 &lt;- lm(read ~ ses + math, d)
arm::display(m3, detail = TRUE)
```

```
## lm(formula = read ~ ses + math, data = d)
##             coef.est coef.se t value Pr(&gt;|t|)
## (Intercept) 17.87     3.52    5.07    0.00   
## seslow      -3.41     1.56   -2.19    0.03   
## sesmiddle   -2.20     1.30   -1.70    0.09   
## math         0.69     0.06   11.44    0.00   
## ---
## n = 200, k = 4
## residual sd = 7.64, R-Squared = 0.45
```

```r
confint(m3)
```

```
##                  2.5 %     97.5 %
## (Intercept) 10.9203275 24.8141011
## seslow      -6.4794276 -0.3358015
## sesmiddle   -4.7509137  0.3584140
## math         0.5692058  0.8063016
```

---
class: inverse center middle

# Model Assumptions

![](http://imgs.xkcd.com/comics/when_you_assume.png)

.footnote[credit: xkcd]

---
# LINE

* **.red[L]**inearity
* **.red[I]**ndependence of residual errors
* Multivariate **.red[N]**ormality
* **.red[E]**qual variance of residual errors (homoscedasticity)

---
# The issue

&lt;div align = "center"&gt;
&lt;img src = ../img/anscombe-quartet.png height = 500&gt;
&lt;/div&gt;

---
# Even better

![](https://d2f99xq7vri1nk.cloudfront.net/DinoSequentialSmaller.gif)

.footnote[https://www.autodeskresearch.com/publications/samestats]

--
### Take home message
Look at your data!


---
# .red[L]inearity

.code-bg-red[


```r
set.seed(8675309)
x &lt;- 0:100
y &lt;- 5 + 10*x + -0.07*x^2 + rnorm(length(x), 0, 20)
sim_data &lt;- data_frame(x = x, y = y)
sim_data
```

```
## # A tibble: 101 x 2
##        x          y
##    &lt;int&gt;      &lt;dbl&gt;
##  1     0  -14.93165
##  2     1   29.36648
##  3     2   12.37582
##  4     3   74.95783
##  5     4   65.18832
##  6     5   72.99439
##  7     6   63.02908
##  8     7   85.02745
##  9     8   91.96133
## 10     9  107.4036 
## # ... with 91 more rows
```

]

---

.code-bg-red[


```r
ggplot(sim_data, aes(x, y)) +
  geom_point() +
  geom_smooth() 
```

![](w4_files/figure-html/smoothed-1.png)&lt;!-- --&gt;
]


---
# .red[I]ndependence of Observations

.pull-left[
* Important x-variable omitted 
* Functional form not modeled correctly
]

.pull-right[
![](../img/dependent-resids.png)
]


---
# Multivariate .red[N]ormality

![](https://scipython.com/static/media/uploads/blog/multivariate_gaussian/bivariate_gaussian.png)

---
![](https://i.stack.imgur.com/B4cuc.png)

---
![](https://i.stack.imgur.com/qqG5Y.png)

---
# Multivariate Outliers
### Example

&gt; In a longitudinal study, you find that the number of letters kindergarten
students can .blue[name] and .blue[provide the correct sound for] both
predict their .red[later (third grade) reading ability].

--

A multivariate outlier would be a student who has an unexpected pattern across
these three variables.


--
e.g., low letter names, extremely high letter sounds, very low later reading achievement

---
# .red[E]qual residual variance
### Homoscedasticity
.gray[Note I've hidden the code here to make the figure larger]


![](w4_files/figure-html/unnamed-chunk-3-1.png)&lt;!-- --&gt;


---
class: inverse
background-image:url(../img/magnify.jpg)
background-size:cover

# Intro to Diagnosing Assumptions

---
# Linearity

.code-bg-red[


```r
ggplot(sim_data, aes(x, y)) +
  geom_point() +
  geom_smooth() +
  geom_smooth(method = "lm",
              color = "magenta")
```

![](w4_files/figure-html/lin-1.png)&lt;!-- --&gt;

]

---
# With our actual data

.pull-left[


```r
ggplot(d, aes(write, math)) +
  geom_point() +
  geom_smooth() +
  geom_smooth(method = "lm",
              color = "magenta")
```

![](w4_files/figure-html/linearity-eval1-1.png)&lt;!-- --&gt;
]

.pull-left[


```r
ggplot(d, aes(read, math)) +
  geom_point() +
  geom_smooth() +
  geom_smooth(method = "lm",
              color = "magenta")
```

![](w4_files/figure-html/linearity-eval2-1.png)&lt;!-- --&gt;
]



---
# Note
This is good evidence, but doesn't guarantee that our MR model
meets the assumptions


---
# Homoscedasticity
You can reproduce the prior plots without the nonlinear fit to visually 
evaluate the variance around the regression line for consistency across the
scale.


---
# Univariate distributions


```r
ggplot(d, aes(read)) +
  geom_histogram(alpha = 0.7)
```

![](w4_files/figure-html/hist1-1.png)&lt;!-- --&gt;

---
# Univariate distributions


```r
ggplot(d, aes(write)) +
  geom_histogram(alpha = 0.7)
```

![](w4_files/figure-html/hist2-1.png)&lt;!-- --&gt;

---
# Univariate distributions


```r
ggplot(d, aes(math)) +
  geom_histogram(alpha = 0.7)
```

![](w4_files/figure-html/hist3-1.png)&lt;!-- --&gt;

---
# Quicker view
(other similar functions exists)

.pull-left[


```r
*library(GGally)
ggscatmat(d, 
          columns = c("math", 
                      "read", 
                      "write"))
```
]

.pull-right[

![](w4_files/figure-html/ggscatmat-eval-1.png)&lt;!-- --&gt;
]


---
# After fitting
* PP-plots (evaluate normality again)
* Linearity (standardized residual plots)
* Independence of errors (standardized residual plots)
* Equal Variance (standardized residual plots)


---
# Inspecting residuals

&gt; Plots of residuals versus fitted values and versus each of the predictors in
turn are the most basic diagnostic graphs.

---

## Let's try with our non-linear model


```r
# Fit model
sim_mod &lt;- lm(y ~ x, sim_data)

# Store residuals and fitted (predicted) values
sim_data$resids &lt;- residuals(sim_mod)
sim_data$fitted &lt;- predict(sim_mod)

# Plot the relation
ggplot(sim_data, aes(fitted, resids)) +
  geom_point() +
  geom_smooth() +
  geom_hline(yintercept = 0,
             size = 3, 
             color = "gray40")
```

---
class: center middle

![](w4_files/figure-html/resid-inspect2-eval-1.png)&lt;!-- --&gt;

---
## What if we model it correctly?


```r
# Model curvilinear trend (we'll talk about this more later)
sim_mod2 &lt;- lm(y ~ x + I(x^2), sim_data)

# Store new residuals and fitted values
sim_data$resids2 &lt;- residuals(sim_mod2)
sim_data$fitted2 &lt;- predict(sim_mod2)

# Plot relation
ggplot(sim_data, aes(fitted2, resids2)) +
  geom_point() +
  geom_smooth() +
  geom_hline(yintercept = 0,
             color = "gray40",
             size = 3)
```

---
class: center middle

![](w4_files/figure-html/correct-curvelin-eval-1.png)&lt;!-- --&gt;

---
# Automated methods


```r
par(mfrow = c(2, 2))
plot(m2)
```

![](w4_files/figure-html/diag-auto-1.png)&lt;!-- --&gt;

---
# QQ Plots
* Last one for today
* Select a specific plot with `which`


```r
plot(m2, which = 2)
```

![](w4_files/figure-html/qq-1.png)&lt;!-- --&gt;
---
# Now: Lab

### Next time
* Other types of residuals
* Outliers &amp; Influence
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="https://platform.twitter.com/widgets.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "atelier-dune-light",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function() {
  var d = document, s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})();</script>

<script>
(function() {
  var i, text, code, codes = document.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
})();
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
